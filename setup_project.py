"""
Script de configuraciÃ³n inicial del proyecto.
Crea directorios necesarios y valida la configuraciÃ³n.

Uso:
    python setup_project.py
"""

import os
from pathlib import Path
import sys

# AÃ±adir directorio raÃ­z al path
sys.path.insert(0, str(Path(__file__).parent))

from config.config import (
    LOGGING_CONFIG, 
    DATA_CONFIG,
    SECURITY_CONFIG,
    print_config_summary
)


def create_directory_structure():
    """Crea la estructura de directorios necesaria."""
    print("=" * 60)
    print("CREANDO ESTRUCTURA DE DIRECTORIOS")
    print("=" * 60)
    
    # Directorios principales
    directories = [
        # Logs y resultados
        LOGGING_CONFIG['log_dir'],
        LOGGING_CONFIG['tensorboard_dir'],
        LOGGING_CONFIG['model_checkpoint_dir'],
        LOGGING_CONFIG['results_dir'],
        
        # Datos
        DATA_CONFIG['data_root'],
        
        # Seguridad (certificados)
        Path(SECURITY_CONFIG.get('certificate_path', './certs')).parent,
    ]
    
    # Crear cada directorio
    for directory in directories:
        dir_path = Path(directory)
        if not dir_path.exists():
            dir_path.mkdir(parents=True, exist_ok=True)
            print(f"âœ“ Creado: {dir_path}")
        else:
            print(f"âœ“ Ya existe: {dir_path}")
    
    print("\n" + "=" * 60)


def verify_dependencies():
    """Verifica que las dependencias estÃ©n instaladas."""
    print("\n" + "=" * 60)
    print("VERIFICANDO DEPENDENCIAS")
    print("=" * 60)
    
    required_packages = [
        ('flwr', 'Flower'),
        ('tensorflow', 'TensorFlow'),
        ('numpy', 'NumPy'),
        ('pandas', 'Pandas'),
        ('sklearn', 'Scikit-learn'),
        ('matplotlib', 'Matplotlib'),
        ('cv2', 'OpenCV')
    ]
    
    missing = []
    
    for package, name in required_packages:
        try:
            __import__(package)
            print(f"âœ“ {name} instalado")
        except ImportError:
            print(f"âœ— {name} NO instalado")
            missing.append(name)
    
    if missing:
        print(f"\nâš  Paquetes faltantes: {', '.join(missing)}")
        print("Ejecuta: pip install -r requirements.txt")
        return False
    else:
        print("\nâœ“ Todas las dependencias estÃ¡n instaladas")
        return True
    
    print("=" * 60)


def check_gpu_availability():
    """Verifica disponibilidad de GPU."""
    print("\n" + "=" * 60)
    print("VERIFICANDO GPU")
    print("=" * 60)
    
    try:
        import tensorflow as tf
        
        gpus = tf.config.list_physical_devices('GPU')
        
        if gpus:
            print(f"âœ“ GPUs disponibles: {len(gpus)}")
            for i, gpu in enumerate(gpus):
                print(f"  GPU {i}: {gpu.name}")
                
            # Configurar memoria dinÃ¡mica
            for gpu in gpus:
                try:
                    tf.config.experimental.set_memory_growth(gpu, True)
                    print(f"  âœ“ Memoria dinÃ¡mica habilitada para {gpu.name}")
                except RuntimeError as e:
                    print(f"  âš  No se pudo configurar memoria dinÃ¡mica: {e}")
        else:
            print("âš  No se detectaron GPUs - se usarÃ¡ CPU")
            print("  El entrenamiento serÃ¡ mÃ¡s lento")
    
    except Exception as e:
        print(f"âœ— Error verificando GPU: {e}")
    
    print("=" * 60)


def create_dataset_readme():
    """Crea README en carpeta de datasets con instrucciones."""
    datasets_path = Path(DATA_CONFIG['data_root'])
    readme_path = datasets_path / 'README.md'
    
    readme_content = """# Datasets para Federated Learning

## Estructura Requerida

Descarga y organiza los datasets en la siguiente estructura:

```
datasets/
â”‚
â”œâ”€â”€ HAM10000/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ ISIC_0024306.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ HAM10000_metadata.csv
â”‚
â”œâ”€â”€ ISIC2018/
â”‚   â”œâ”€â”€ ISIC2018_Task3_Training_Input/
â”‚   â”‚   â”œâ”€â”€ ISIC_0000000.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ISIC2018_Task3_Training_GroundTruth.csv
â”‚
â”œâ”€â”€ ISIC2019/
â”‚   â”œâ”€â”€ ISIC_2019_Training_Input/
â”‚   â”‚   â”œâ”€â”€ ISIC_0000000.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ISIC_2019_Training_GroundTruth.csv
â”‚
â”œâ”€â”€ ISIC2020/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ ISIC_0000000.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ train.csv
â”‚
â””â”€â”€ PH2/
    â”œâ”€â”€ images/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ PH2_dataset.csv
```

## Fuentes de Datos

### HAM10000 (Primary Node)
- **Fuente**: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T
- **Clases**: 7 tipos de lesiones cutÃ¡neas
- **TamaÃ±o**: ~10,015 imÃ¡genes

### ISIC 2018 Challenge (Node 1)
- **Fuente**: https://challenge.isic-archive.com/data/#2018
- **Task 3**: Lesion Diagnosis
- **Clases**: 7 tipos de lesiones

### ISIC 2019 Challenge (Node 3)
- **Fuente**: https://challenge.isic-archive.com/data/#2019
- **Clases**: 8 tipos (9 con "Unknown")
- **TamaÃ±o**: ~25,331 imÃ¡genes

### ISIC 2020 Challenge (Node 2)
- **Fuente**: https://challenge.isic-archive.com/data/#2020
- **Enfoque**: Binary classification (malignant/benign)
- **TamaÃ±o**: ~33,126 imÃ¡genes

### PH2 (External Validation)
- **Fuente**: https://www.fc.up.pt/addi/ph2%20database.html
- **Uso**: Solo para validaciÃ³n externa final
- **TamaÃ±o**: 200 imÃ¡genes dermoscÃ³picas

## Notas Importantes

1. **Preprocesamiento**: Todas las imÃ¡genes se redimensionarÃ¡n a 224Ã—224
2. **Balance**: Se aplicarÃ¡n class weights y data augmentation
3. **Splits**: 70% train, 15% val, 15% test
4. **IID/Non-IID**: Configurable para simulaciones realistas

## Licencias

Cada dataset tiene su propia licencia. Verifica los tÃ©rminos de uso:
- HAM10000: CC BY-NC 4.0
- ISIC Challenges: Terms available at isic-archive.com
- PH2: Academic use only
"""
    
    readme_path.write_text(readme_content, encoding='utf-8')
    print(f"\nâœ“ README de datasets creado: {readme_path}")


def print_next_steps():
    """Imprime los siguientes pasos."""
    print("\n" + "=" * 60)
    print("CONFIGURACIÃ“N COMPLETADA")
    print("=" * 60)
    print("\nðŸ“‹ PRÃ“XIMOS PASOS:\n")
    print("1. Descargar datasets (ver datasets/README.md)")
    print("2. Verificar estructura de carpetas")
    print("3. Probar carga de datos:")
    print("   python -m data.data_loader")
    print("\n4. Iniciar servidor:")
    print("   python main_server.py --strategy FedAvg --rounds 50")
    print("\n5. Iniciar clientes (en terminales separadas):")
    print("   python main_client.py --node-id 0 --dataset HAM10000")
    print("   python main_client.py --node-id 1 --dataset ISIC2018")
    print("   python main_client.py --node-id 2 --dataset ISIC2020")
    print("   python main_client.py --node-id 3 --dataset ISIC2019")
    print("\n6. Monitorear con TensorBoard:")
    print("   tensorboard --logdir=logs/tensorboard")
    print("\n" + "=" * 60)


def main():
    """Ejecuta la configuraciÃ³n inicial."""
    print("\n" + "ðŸš€ " * 20)
    print("CONFIGURACIÃ“N INICIAL DEL PROYECTO")
    print("Federated Learning - ClasificaciÃ³n de CÃ¡ncer de Piel")
    print("ðŸš€ " * 20 + "\n")
    
    # Mostrar configuraciÃ³n
    print_config_summary()
    
    # Crear estructura de directorios
    create_directory_structure()
    
    # Crear README de datasets
    create_dataset_readme()
    
    # Verificar dependencias
    deps_ok = verify_dependencies()
    
    # Verificar GPU
    check_gpu_availability()
    
    # Siguiente pasos
    print_next_steps()
    
    if not deps_ok:
        print("\nâš  ATENCIÃ“N: Instala las dependencias faltantes antes de continuar")
        return 1
    
    print("\nâœ… Â¡Sistema configurado correctamente!\n")
    return 0


if __name__ == '__main__':
    exit(main())
